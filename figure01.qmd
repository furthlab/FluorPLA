---
title: "figure01"
author: "Daniel FÃ¼rth <br><br>Table of Contents:"
format: gfm
toc: true
---

## Emission plot Fig. 1c

```{r}
files<-dir('data/spectra/emission', full.names = TRUE)

spectra<-read.table(files[1], sep='\t')
spectra$sample <- 1

for(i in seq_along(files)[-1]){
  spectra.tmp <-read.table(files[i], sep='\t')
  spectra.tmp$sample <- i
  spectra <- rbind(spectra, spectra.tmp)
}
```

```{r}
spectra$fluor <- NA

spectra$fluor[spectra$sample %in% seq(9,17)] <- 594
spectra$fluor[!(spectra$sample %in% seq(9,17))] <- 488

spectra$status <- NA

status<-c('fluor', 'quench', 'fluor',
          'quench', 'quench', 'unquench',
          'unquench', 'unquench', 'unquench',
          'fluor', 'fluor', 'fluor',
          'quench', 'quench', 'quench',
          'unquench', 'unquench', 'unquench')
k<-1
for(i in unique(spectra$sample)){
  
  
  spectra$status[spectra$sample==i]<-status[i]

}


library(dplyr)
spec<- spectra %>% 
  group_by(fluor, status, V3) %>% 
  summarise(emission=mean(V4))

spec$emission[spec$fluor == 488]<-spec$emission[spec$fluor == 488]/max(spec$emission[spec$fluor == 488 & spec$status == 'fluor'])
spec$emission[spec$fluor == 594]<-spec$emission[spec$fluor == 594]/max(spec$emission[spec$fluor == 594 & spec$status == 'fluor'])

spec$emission <- spec$emission - mean(spec$emission[1:50])


col2hex <- function(cname)
{
  colMat <- col2rgb(cname)
  rgb(
    red=colMat[1,]/255,
    green=colMat[2,]/255,
    blue=colMat[3,]/255
  )
}

spec<- spec[-which(spec$status == 'unquench'),]

quartz(width = 130.1729/20, height = 83.8626/20)
par(yaxs='i', xaxs='i', mar=c(4,4,1,1))
plot(0,0, type='n', xlim=c(450,750), ylim=c(0,1), ylab='Emission', xlab="Wavelength (nm)", las=1, axes=F)
axis(2, las=1, at=c(0,0.5,1))

color <- c('green3', 'green4', 'red', 'red4')
unique_samples <- unique( paste(spec$fluor, spec$status) )
names(spec)<-c("fluor" ,   "status" ,  "wavelength"     ,  "emission")

peak.max <- numeric()
# Loop through each unique sample and create a polygon plot
for (sample_name in unique_samples) {
  # Subset the data for the current sample
  sample_data <- spec[paste(spec$fluor, spec$status) == sample_name, ]
  
  # Create a polygon plot for the current sample
  polygon(c(sample_data$wavelength, 
            sample_data$wavelength[nrow(sample_data)], 
            sample_data$wavelength[1],
            sample_data$wavelength[1]), 
          
          c(sample_data$emission, 0, 0, sample_data$emission[1]), 
          col = paste0( col2hex( color[match(sample_name, unique_samples)] ), '70' ),
          border = color[match(sample_name, unique_samples)], lwd=2, xpd=F )
  
  # Add a legend for sample names
  legend("topright", legend = unique_samples, fill = color)
  
  peak.max <- c(peak.max, sample_data$wavelength[which.max(sample_data$emission)] )
}

axis(1, at=seq(300,800,by=50))

peak.max
```

Save the plot.

```{r}
quartz.save(file="pdf/figure01_c.pdf", type='pdf')
```

Then compute quench ratio:
```{r}
quench.ratio <- spec %>% group_by(fluor, status) %>% summarise(max(emission))

AZdye488<-quench.ratio$`max(emission)`[1]/quench.ratio$`max(emission)`[2]

AZdye594<-quench.ratio$`max(emission)`[3]/quench.ratio$`max(emission)`[4]

round(AZdye488, 2)
round(AZdye594, 2)
```

## DAPI nuclei cell segmentation in 2D.

### Installation

Make sure you have `conda` installed.
Create a new conda environment:
```{eval=FALSE}
conda create --name cellseg2D-env
conda activate cellseg2D-env
conda install -c conda-forge napari   
conda install opencv
```

Install Tensorflow for macOS M1/M2:
```{eval=FALSE}
pip install tensorflow-macos
pip install tensorflow-metal
```

Install stardist for cell nuclei segmentation:
```{eval=FALSE}
pip install gputools
pip install stardist
pip install csbdeep
```

### Segmentation training

#### Augment training data set

```{eval=FALSE}
python augment.py
```

This expands images_org and masks_org into images (input) and masks (ground truth). Input and ground truth are matched based on file name. Format is 8-bit monochrome TIF on both.

If more than 255 cells needs to be segmented within a single image you can simply change mask format to 16-bit.

#### Perform training

```{eval=FALSE}
python train_nuclei.py
```

Open up tensorboard to follow the results:
```{eval=FALSE}
tensorboard --logdir=.
```



![Tensorboard lets you monitor the training of the neural network](./repo_img/tensorboard.png)


Click the **images** tab of the Tensorboard to inspect the visual output of the training.


::: {#fig-training layout-ncol=2}
![begin](./repo_img/tensorboard_img.png){#fig-begin width=40%}
![later](./repo_img/tensorboard_later.png){#fig-later width=40%} 

Training monitoring. Left is in the beginning right is later during training. Top row is input, middle is output of network and bottom is the reference (what the network should aim for).
:::

In detail:

- `net_input` is the input images. Notice a cell is only really present in the first out of three.
- `net_output0` is the current output from the network.
- `net_target0` is the ground truth (what the network ideally should have generated).

### Prediction

We have a script we can apply to any image for prediction.

```{eval=FALSE}
python predict_nuclei.py 
```

::: {#fig-dapi layout-ncol=2}

![input](./repo_img/example_image.jpg){#fig-input}

![output](./repo_img/example_labels.jpg){#fig-output}

Segmentation results.
:::
